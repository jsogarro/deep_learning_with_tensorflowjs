# Preface

The purpose of this book is to provide a gentle introduction to the topics of machine learning, deep learning and TensorFlow.js. It is intended for JavaScript web developers that want to learn how embed deep learning models into their products.

This books assumes familiarity with JavaScript and not experience with TensorFlow, machine learning and deep learning. The intent is to teach JavaScript/Node developers just enough theory to understand what the deep learning models weʼll be working with are doing under the hood.

As weʼll learn in this manuscript, one does not have to be an expert to embed deep learning models into a web based application. This book should be read as a tutorial that will introduce you to the topics of artificial intelligence, machine learning and deep learning. We will then learn about TensorFlow, itʼs beginnings and the TensorFlow.js library.

The intent of this book is not to make you an expert in machine learning or deep learning for that matter. What you will learn is how to use TFJS in its optimal use case, which is to embed existing machine learning models into the client of a web application to perform inference (this is a term that, recently, has been assigned new meaning by the deep learning community to denote the testing process, or out of sample testing, however it is an old term in the statistical community, i.e. statistical inference, which is quite different and, in short refers to: selecting a statistical model, and then learning parameters of the model to explain the observed data), and/or retrain these models. JavaScript is not the ideal language to be used for the complete mathematical operations that are usually done with machine learning algorithms when working with the Python version of the library. We will use JS to recreate some basic models using small datasets to demonstrate how they work and how TFJS can be used to create them but this is not the primary use case of the language. In the later chapters we will focus on where TensorFlow.js really shines by importing pre-trained models into the browser and using them to infer results from user input from the browser in real-time.

The reason for this is that in the python ecosystem we have tools such as NumPy and Pandas that helps us make sense of data and perform complex linear transformations on our data very quickly. Attempting to train complex models in the browser is not very realistic and is a task that is better suited for Python, C and C++. When it comes to speed, Python is very slow for most things, and almost all ML libraries use C/C++ backends. The biggest advantage of Python is the rapid prototyping capabilities, the fact that the code is very easy to read, write and maintain when compared to C/C++. The limited memory space in the browser does not make for an environment that is friendly to the machine learning training process. Though we could perform this in Node leveraging the speed and absolute raw power of the V8 run-time on the server we still lack the ability to perform efficient numerical operations. Thus our focus on developing and deploying applications that leverage deep learning models will primary focus on embedding existing models into the browser. We have to note that for some small models, training in TFJS can be faster than in TF due to the Python interpreter being slow. Also there is no Tensorboard capability for TFJS (only for scalars). However GPU computation is used automatically in TFJS (even if one is using an integrated video card, we'll see in the first chapter more details about using the GPU and speed in TFJS compared to TF) whereas in TF installing CUDA is necessary and there is no integrated card support.

A note that is worth mentioning is that though loading pre-trained models in the browser is the current best best practice when it comes to embedding deep learning models into a browser-based application we are limited by the size of the model. If a model is too heavy it would not make sense to load into our web applications on the client side since it could potentially slow down our load times and create a poor user experience for our users. The types of models that will allow TFJS to shine on the client side are smaller models that have been specifically designed to run inside of the browser or smaller devices (i.e. iPhones and Android devices).

If you are curious to learn the types of deep learning models we will be building and working with in this course we will take a look at regression, logistic regression, Convolutional Neural Networks (CNN) and \_\_\_\_.

With that being said we will now get into the chapters that will take you from deep learning novice to being a developer with enough background on deep learning and TensorFlow.js to embed simple models into your Node.js applications.
